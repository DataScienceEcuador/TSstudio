---
title: "Forecasting Applications"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Forecasting Applications}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  
  ```{r, include = FALSE}
knitr::opts_chunk$set(
fig.width=8, 
fig.height=5,
warning = FALSE, 
message = FALSE,
collapse = TRUE,
comment = "#>"
)
```

The **TSstudio** package provides a set of functions for train, test, and evaluate time series forecasting models, this vignette covers the main ones.


## Creating testing and training partitons

The `ts_split` function split time series data into training (sample-in) and testing (sample-out) partitions, keeping the chronological order of the series. The `sample.out` argument defines the length of the testing partition. In the following example, we will use the function to split the `USgas` series (the monthly demand for natural gas in the US) into training and testing partitions, leaving the last 12 months as testing partition:

```{r}
library(TSstudio)

data(USgas)

ts_info(USgas)

USgas_par <- ts_split(USgas, sample.out = 12)

train <- USgas_par$train

test <- USgas_par$test

ts_info(train)
ts_info(test)


```


## Visualize forecast performance 

The `test_forecast` function visualizes the performance of a forecasting model on the training and testing partitions by plotting the fitted and forecasted values against the actuals. The function supports forecast models from the `forecast` and `stats` packages such as `auto.arima`, `tslm`, `ets`, `HoltWinters`, etc.


For example, let's train a `tslm` model on the `train` partition and forecast the corresponding observations of the `test` partition:

```{r}
library(forecast)

md <- tslm(train ~ season + trend)

fc <- forecast(md, h = 12)
```

Using the actual series (`USgas`), forecast object (`fc`), and the corresponding testing partition (`test`), the function will plot the fitted and forecasted values against the actuals:

```{r}
test_forecast(actual = USgas,
              forecast.obj = fc,
              test = test)
```

The MAPE and RMSE score of both the fitted and forecasted values can be seen when hovering on the plot. 

## Training multiple time series model with backtesting

The `train_model` function replaces the `ts_backtesting` function, which will deprecate on the next version. The function provides a flexible framework for forecasting. The use of the function is for train, test, and evaluate multiple models (or different versions of those models) with the use of a backtesting approach. The backtesting approach enables you to evaluate the performance of the model over time (as opposed to single training and testing partitions) and select a model that performed best using some error criteria (e.g., **MAPE** or **RMSE**). The main arguments of this function are:


* `methods` - defines the type of models and their setting to be used on the training process. Currently, it supports the following models:

+ `arima` - model from the stats package
+ `auto.arima` - model from the forecast package
+ `ets` - model from the forecast package
+ `HoltWinters` - model from the stats package
+ `nnetar` - model from the forecast package
+ `tslm` - model from the forecast package (note that the 'tslm' model must have the formula argument in the 'method_arg' argument)

The `method` argument defines as a `list` and using the following structure:

```{r, eval = FALSE}

list(model_1_id = list(method = "[type of model]",
                       method_arg = list("[model 1 arguments]"),
                       notes = "[set notes for model 1]"),
     .
     .
     .
     model_n_id = list(method = "[type of model]",
                       method_arg = list("[model n arguments]"),
                       notes = "[set notes for model n]"))

```


Where each element of the list defines the specific model and its setting. The name of the element represents the model ID, and it has three arguments:
`method` - the type of model to use (one of the listed models above)
`method_arg` - a list (optional), enables you to modify the default setting of the model argument
`notes` - a character (optional), allows you to set notes about the model. This useful when testing multiple versions of the same models


* `train_method` - a list, set the window structure of the backtesting process, where:
+ `partitions` - set the number of partitions to use on the backtesting
+ `sample.out` - set the length of the testing partitions
+ `space` - defines the expansion length of the backtesting window

**Note:** by default, the backtesting algorithm is using the expending window approach. Alternatively, it is possible to use a sliding window approach by setting the `sample.in` argument. 


The following example demonstrated the use of the `train_model` function to forecast the demand for natural gas in the next 12 months. Let's first defines the forecasting methods:

```{r}
methods <- list(ets1 = list(method = "ets",
                            method_arg = list(opt.crit = "lik"),
                            notes = "ETS model with opt.crit = lik"),
                ets2 = list(method = "ets",
                            method_arg = list(opt.crit = "amse"),
                            notes = "ETS model with opt.crit = amse"),
                arima1 = list(method = "arima",
                              method_arg = list(order = c(2,1,0)),
                              notes = "ARIMA(2,1,0)"),
                arima2 = list(method = "arima",
                              method_arg = list(order = c(2,1,2),
                                                seasonal = list(order = c(1,1,1))),
                              notes = "SARIMA(2,1,2)(1,1,1)"),
                hw = list(method = "HoltWinters",
                          method_arg = NULL,
                          notes = "HoltWinters Model"),
                tslm = list(method = "tslm",
                            method_arg = list(formula = input ~ trend + season),
                            notes = "tslm model with trend and seasonal components"))

```

Similarly, we will define the window structure of the backtesting by using:

* Six testing partitions
* Each partition with a length of 12 observations, and
* Expending rate of the backtesting window of 3 observations  

```{r}
train_method = list(partitions = 6,
                    sample.out = 12,
                    space = 3)
```

We will now set the `train_model` function, using the `methods` and `train_method` lists to set the corresponding arguments of the function. The `horizon` argument defines the length of the forecast, and the `error` argument defines the error metric to use to evaluate the performance of the models:

```{r}
md <- train_model(input = USgas,
                  methods = methods,
                  train_method = train_method,
                  horizon = 12,
                  error = "MAPE")

```

The function returns a leaderboard table sorting the models by the selected error metric (which in this case was MAPE). In addition to the average MAPE and RMSE error of the models on the testing partitions, the function returns the average coverage rate of the prediction intervals. The coverage rate represents the percentage of actual observations that were bounded between the prediction intervals. As closer the coverage rate to the level rate of the prediction intervals (e.g., 95%), the more reliable the prediction intervals are. For instance, the prediction intervals of the best model, `arima2`, had average coverage of 58% and 80% for the corresponding 80% and 95% prediction intervals. 




```{r}
plot_model(md)

plot_error(md)
```



